{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare NLP Techniques: Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read In Cleaned Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned training and test sets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train = pd.read_csv('data/X_train.csv')\n",
    "X_test = pd.read_csv('data/X_test.csv')\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "y_test = pd.read_csv('data/y_test.csv')\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit a TFIDF vectorizer and then use that trained vectorizer\n",
    "# to transform the messages in the training and test sets\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(X_train['clean_text'])\n",
    "X_train_vect = tfidf_vect.transform(X_train['clean_text'])\n",
    "X_test_vect = tfidf_vect.transform(X_test['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What words did the vectorizer learn?\n",
    "tfidf_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit RandomForestClassifier On Top Of TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a basic Random Forest model on these vectors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(X_train_vect, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to make predictions on the test data\n",
    "y_pred_tfidf = rf_model.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions of the model on the holdout test set\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_tfidf = precision_score(y_test, y_pred_tfidf)\n",
    "recall_tfidf = recall_score(y_test, y_pred_tfidf)\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision_tfidf, 3), round(recall_tfidf, 3), round((y_pred_tfidf==y_test['label']).sum()/len(y_pred_tfidf), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create word2vec Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a basic word2vec model\n",
    "import gensim\n",
    "\n",
    "w2v_model = gensim.models.Word2Vec(X_train,\n",
    "                                   vector_size=100,\n",
    "                                   window=5,\n",
    "                                   min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the words in each text message with the learned word vector\n",
    "words = set(w2v_model.wv.index_to_key)\n",
    "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in X_train['clean_text']])\n",
    "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in X_test['clean_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average the word vectors for each sentence (and assign a vector of zeros if the model\n",
    "# did not learn any of the words in the text message during training\n",
    "X_train_vect_avg = []\n",
    "for v in X_train_vect:\n",
    "    if v.size:\n",
    "        X_train_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_train_vect_avg.append(np.zeros(100, dtype=float))\n",
    "        \n",
    "X_test_vect_avg = []\n",
    "for v in X_test_vect:\n",
    "    if v.size:\n",
    "        X_test_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_test_vect_avg.append(np.zeros(100, dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What does the unaveraged version look like?\n",
    "X_train_vect[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What does the averaged version look like?\n",
    "X_train_vect_avg[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit RandomForestClassifier On Top Of Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit a basic Random Forest model on top of the vectors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(X_train_vect_avg, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to make predictions on the test data\n",
    "y_pred_word2vec = rf_model.predict(X_test_vect_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions of the model on the holdout test set\n",
    "precision_word2vec = precision_score(y_test, y_pred_word2vec)\n",
    "recall_word2vec = recall_score(y_test, y_pred_word2vec)\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision_word2vec, 3), round(recall_word2vec, 3), round((y_pred_word2vec==y_test['label']).sum()/len(y_pred_word2vec), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create doc2vec Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created TaggedDocument vectors for each text message in the training and test sets\n",
    "tagged_docs_train = [gensim.models.doc2vec.TaggedDocument(v, [i])\n",
    "                     for i, v in enumerate(X_train['clean_text'])]\n",
    "tagged_docs_test = [gensim.models.doc2vec.TaggedDocument(v, [i])\n",
    "                    for i, v in enumerate(X_test['clean_text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do these TaggedDocument objects look like?\n",
    "tagged_docs_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a basic doc2vec model\n",
    "d2v_model = gensim.models.Doc2Vec(tagged_docs_train, \n",
    "                                  vector_size=100,\n",
    "                                  window=5,\n",
    "                                  min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer the vectors to be used in training and testing\n",
    "train_vectors = [d2v_model.infer_vector(eval(v.words)) for v in tagged_docs_train]\n",
    "test_vectors = [d2v_model.infer_vector(eval(v.words)) for v in tagged_docs_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit RandomForestClassifier On Top Of Document Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a basic model, make predictions on the holdout test set, and the generate the evaluation metrics\n",
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(train_vectors, y_train.values.ravel())\n",
    "\n",
    "y_pred_doc2vec = rf_model.predict(test_vectors)\n",
    "\n",
    "precision_doc2vec = precision_score(y_test, y_pred_doc2vec)\n",
    "recall_doc2vec = recall_score(y_test, y_pred_doc2vec)\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision_doc2vec, 3), round(recall_doc2vec, 3), round((y_pred_doc2vec==y_test['label']).sum()/len(y_pred_doc2vec), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Data for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Train the tokenizer and use that tokenizer to convert the sentences to sequences of numbers\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train['clean_text'])\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train['clean_text'])\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences so each sequence is the same length\n",
    "X_train_seq_padded = pad_sequences(X_train_seq, 50)\n",
    "X_test_seq_padded = pad_sequences(X_test_seq, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build And Evaluate RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tools needed from keras and define functions to calculate recall and precision\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.models import Sequential\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the basic RNN model framework\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(tokenizer.index_word)+1, 32))\n",
    "model.add(LSTM(32, dropout=0, recurrent_dropout=0))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the RNN\n",
    "history = model.fit(X_train_seq_padded, y_train['label'], \n",
    "                    batch_size=32, epochs=10,\n",
    "                    validation_data=(X_test_seq_padded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot basic evaluation metrics across epochs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for i in ['accuracy', 'precision_m', 'recall_m']:\n",
    "    acc = history.history[i]\n",
    "    val_acc = history.history['val_{}'.format(i)]\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "    plt.title('Results for {}'.format(i))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "precision_rnn = history.history['val_precision_m']\n",
    "recall_rnn = history.history['val_recall_m']\n",
    "accuracy_rnn = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TFIDF -- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision_tfidf, 3), round(recall_tfidf, 3), round((y_pred_tfidf==y_test['label']).sum()/len(y_pred_tfidf), 3)))\n",
    "print('W2V -- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision_word2vec, 3), round(recall_word2vec, 3), round((y_pred_word2vec==y_test['label']).sum()/len(y_pred_word2vec), 3)))\n",
    "print('D2V -- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision_doc2vec, 3), round(recall_doc2vec, 3), round((y_pred_doc2vec==y_test['label']).sum()/len(y_pred_doc2vec), 3)))\n",
    "print('RNN -- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision_rnn[-1], 3), round(recall_rnn[-1], 3), round(accuracy_rnn[-1], 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
